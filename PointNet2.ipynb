{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from path import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9ef13b2",
   "metadata": {},
   "source": [
    "### Попередня обробка даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5461d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Select_Points(object):\n",
    "    def __init__(self, out_size_points):\n",
    "        # вибір кількості точок фігури \n",
    "        self.out_size_points = out_size_points\n",
    "\n",
    "    def __call__(self, mesh):\n",
    "        # вершини та грані\n",
    "        vertices, faces = mesh\n",
    "        vertices = np.array(vertices)\n",
    "        areas = np.zeros(len(faces))\n",
    "        \n",
    "        # площа кожної грані(трикутника)\n",
    "        for i, face in enumerate(faces):\n",
    "            v0, v1, v2 = vertices[face]\n",
    "            a = np.linalg.norm(v1 - v0)\n",
    "            b = np.linalg.norm(v2 - v1)\n",
    "            c = np.linalg.norm(v0 - v2)\n",
    "            s = 0.5 * (a + b + c)\n",
    "            areas[i] = max(s * (s - a) * (s - b) * (s - c), 0) ** 0.5\n",
    "\n",
    "        sampled_faces = random.choices(faces, weights=areas, k=self.out_size_points)\n",
    "        sampled_points = np.zeros((self.out_size_points, 3))\n",
    "\n",
    "        # Вибір точок випадковим чином на кожній грані\n",
    "        for i, face in enumerate(sampled_faces):\n",
    "            v0, v1, v2 = vertices[face]\n",
    "            s, t = sorted([random.random(), random.random()])\n",
    "            point = (s * v0 + (t - s) * v1 + (1 - t) * v2)\n",
    "            sampled_points[i] = point\n",
    "\n",
    "        return sampled_points\n",
    "    \n",
    "class Normalize(object):\n",
    "    # нормалізація вхідних точок на основі хмар точок\n",
    "    def __call__(self, point_cloud):\n",
    "        normalized_point_cloud = point_cloud - np.mean(point_cloud, axis=0) \n",
    "        normalized_point_cloud /= np.max(np.linalg.norm(normalized_point_cloud, axis=1))\n",
    "        return  normalized_point_cloud\n",
    "    \n",
    "class ToTensor(object):\n",
    "    # конвертація масиву хмар точок в PyTorch tensor,\n",
    "    # для побудови архітектури нейронної мережі\n",
    "    def __call__(self, point_cloud):\n",
    "        array = torch.from_numpy(point_cloud)\n",
    "        return array.type(torch.DoubleTensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d900df1",
   "metadata": {},
   "source": [
    "### Набір даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRead(Dataset):\n",
    "    # завантажує дані про об'єкти (клас і шлях) з датасетів для тренування та тестування\n",
    "    def __init__(self, root_dir, subfolder=None, transform=None):\n",
    "        self.transform = transform\n",
    "        folders = [folder for folder in sorted(os.listdir(root_dir)) if os.path.isdir(os.path.join(root_dir, folder))]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.files = []\n",
    "        \n",
    "        for class_name in self.classes.keys():\n",
    "            new_dir = os.path.join(root_dir, class_name, subfolder)\n",
    "            for file_name in os.listdir(new_dir):\n",
    "                if file_name.endswith('.off'):\n",
    "                    sample = {}\n",
    "                    sample['File_Path'] = os.path.join(new_dir, file_name)\n",
    "                    sample['Class'] = class_name\n",
    "                    self.files.append(sample)\n",
    "\n",
    "    # повертає кількість елементів датасету\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    # завантажує конкретний файл\n",
    "    # і застосовує до нього певне \n",
    "    # перетворення даних (якщо є)\n",
    "    def __getitem__(self, idx):            \n",
    "        file_path = self.files[idx]['File_Path']\n",
    "        class_name = self.files[idx]['Class']\n",
    "        datapoint = None\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            off_header = file.readline().strip()\n",
    "            if 'OFF' == off_header:\n",
    "                num_vertices, num_faces, _ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "            else:\n",
    "                num_vertices, num_faces, _ = tuple([int(s) for s in off_header[3:].split(' ')])\n",
    "            \n",
    "            vertices = [[float(s) for s in file.readline().strip().split(' ')] for _ in range(num_vertices)]\n",
    "            faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for _ in range(num_faces)]\n",
    "            \n",
    "            if self.transform:\n",
    "                datapoint = self.transform((vertices, faces))\n",
    "        \n",
    "        return {\n",
    "            'Data': datapoint, \n",
    "            'Class': self.classes[class_name]\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2b21f18",
   "metadata": {},
   "source": [
    "### Допоміжні функції"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обчислює квадрат відстані між двома наборами точок\n",
    "def square_distance(src, dst):\n",
    "    batch_size, num_src, _ = src.shape\n",
    "    _, num_dst, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(batch_size, num_src, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(batch_size, 1, num_dst)\n",
    "    return dist\n",
    "\n",
    "# Виконує індексацію вздовж пакету та розмірів точок, дозволяючи ефективно вибирати точки з пакету хмар точок\n",
    "def index_points(points, indices):\n",
    "    device = points.device\n",
    "    batch_size = points.shape[0]\n",
    "    view_shape = list(indices.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(indices.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(batch_size, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, indices, :]\n",
    "    return new_points\n",
    "\n",
    "# Виконує вибірку найдальших точок, щоб вибрати фіксовану кількість репрезентативних точок із певної хмари точок\n",
    "def farthest_point_sample(xyz, num_points):\n",
    "    device = xyz.device\n",
    "    batch_size, num_points_src, _ = xyz.shape\n",
    "    centroids = torch.zeros(batch_size, num_points, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(batch_size, num_points_src).to(device) * 1e10\n",
    "    farthest = torch.randint(0, num_points_src, (batch_size,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(batch_size, dtype=torch.long).to(device)\n",
    "    for i in range(num_points):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(batch_size, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "# Запитує індекси точок, які лежать у заданому радіусі кожної точки\n",
    "def query_ball_point(radius, num_samples, xyz, new_xyz):\n",
    "    device = xyz.device\n",
    "    batch_size, num_points, _ = xyz.shape\n",
    "    _, num_new_points, _ = new_xyz.shape\n",
    "    group_indices = torch.arange(num_points, dtype=torch.long).to(device).view(1, 1, num_points).repeat([batch_size, num_new_points, 1])\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    group_indices[sqrdists > radius ** 2] = num_points\n",
    "    group_indices = group_indices.sort(dim=-1)[0][:, :, :num_samples]\n",
    "    group_first = group_indices[:, :, 0].view(batch_size, num_new_points, 1).repeat([1, 1, num_samples])\n",
    "    mask = group_indices == num_points\n",
    "    group_indices[mask] = group_first[mask]\n",
    "    return group_indices\n",
    "\n",
    "# Поєднує наведені вище методи для вибірки фіксованої кількості точок із певної хмари точок\n",
    "def sample_and_group(num_points, radius, num_samples, xyz, points, returnfps=False):\n",
    "    batch_size, num_input_points, _ = xyz.shape\n",
    "    num_output_points = num_points\n",
    "    fps_indices = farthest_point_sample(xyz, num_points)\n",
    "    new_xyz = index_points(xyz, fps_indices)\n",
    "    indices = query_ball_point(radius, num_samples, xyz, new_xyz)\n",
    "    grouped_xyz = index_points(xyz, indices)\n",
    "    grouped_xyz_norm = grouped_xyz - new_xyz.view(batch_size, num_output_points, 1, -1)\n",
    "    if points is not None:\n",
    "        grouped_points = index_points(points, indices)\n",
    "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1)\n",
    "    else:\n",
    "        new_points = grouped_xyz_norm\n",
    "    if returnfps:\n",
    "        return new_xyz, new_points, grouped_xyz, fps_indices\n",
    "    else:\n",
    "        return new_xyz, new_points\n",
    "\n",
    "# Вибирає всі точки з даної хмари точок і групує їх разом\n",
    "def sample_and_group_all(xyz, points):\n",
    "    device = xyz.device\n",
    "    batch_size, num_points, num_dims = xyz.shape\n",
    "    new_xyz = torch.zeros(batch_size, 1, num_dims).to(device)\n",
    "    grouped_xyz = xyz.view(batch_size, 1, num_points, num_dims)\n",
    "    if points is not None:\n",
    "        new_points = torch.cat([grouped_xyz, points.view(batch_size, 1, num_points, -1)], dim=-1)\n",
    "    else:\n",
    "        new_points = grouped_xyz\n",
    "    return new_xyz, new_points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f34621ed",
   "metadata": {},
   "source": [
    "### Архітектури допоміжних нейронних мереж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp):\n",
    "        super(PNetSetAbstraction, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        xyz = xyz.permute(0, 2, 1)\n",
    "        if points is not None:\n",
    "            points = points.permute(0, 2, 1)\n",
    "\n",
    "        new_xyz = index_points(xyz, farthest_point_sample(xyz, self.npoint))\n",
    "        group_idx = query_ball_point(self.radius, self.nsample, xyz, new_xyz)\n",
    "        grouped_xyz = index_points(xyz, group_idx)\n",
    "        grouped_xyz -= new_xyz.view(-1, self.npoint, 1, 3)\n",
    "        if points is not None:\n",
    "            grouped_points = index_points(points, group_idx)\n",
    "            grouped_points = torch.cat([grouped_points, grouped_xyz], dim=-1)\n",
    "        else:\n",
    "            grouped_points = grouped_xyz\n",
    "\n",
    "        grouped_points = grouped_points.permute(0, 3, 2, 1)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            grouped_points = F.relu(bn(conv(grouped_points)))\n",
    "\n",
    "        new_points = torch.max(grouped_points, 2)[0]\n",
    "        new_xyz = new_xyz.permute(0, 2, 1)\n",
    "        return new_xyz, new_points\n",
    "\n",
    "\n",
    "class PNetSetAbstractionMsg(nn.Module):\n",
    "    def __init__(self, npoint, radius_list, nsample_list, in_channel, mlp_list):\n",
    "        super(PNetSetAbstractionMsg, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius_list = radius_list\n",
    "        self.nsample_list = nsample_list\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        self.bn_blocks = nn.ModuleList()\n",
    "        last_channel = in_channel + 3\n",
    "        for mlp in mlp_list:\n",
    "            convs = nn.ModuleList()\n",
    "            bns = nn.ModuleList()\n",
    "            for out_channel in mlp:\n",
    "                convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "                bns.append(nn.BatchNorm2d(out_channel))\n",
    "                last_channel = out_channel\n",
    "            self.conv_blocks.append(convs)\n",
    "            self.bn_blocks.append(bns)\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        xyz = xyz.permute(0, 2, 1)\n",
    "        if points is not None:\n",
    "            points = points.permute(0, 2, 1)\n",
    "\n",
    "        B, N, C = xyz.shape\n",
    "        S = self.npoint\n",
    "        new_xyz = index_points(xyz, farthest_point_sample(xyz, S))\n",
    "        new_points_list = []\n",
    "        for i, radius in enumerate(self.radius_list):\n",
    "            K = self.nsample_list[i]\n",
    "            group_idx = query_ball_point(radius, K, xyz, new_xyz)\n",
    "            grouped_xyz = index_points(xyz, group_idx)\n",
    "            grouped_xyz -= new_xyz.view(B, S, 1, C)\n",
    "            if points is not None:\n",
    "                grouped_points = index_points(points, group_idx)\n",
    "                grouped_points = torch.cat([grouped_points, grouped_xyz], dim=-1)\n",
    "            else:\n",
    "                grouped_points = grouped_xyz\n",
    "\n",
    "            grouped_points = grouped_points.permute(0, 3, 2, 1)\n",
    "            for j, conv in enumerate(self.conv_blocks[i]):\n",
    "                bn = self.bn_blocks[i][j]\n",
    "                grouped_points = F.relu(bn(conv(grouped_points)))\n",
    "\n",
    "            new_points = torch.max(grouped_points, 2)[0]\n",
    "            new_points_list.append(new_points)\n",
    "\n",
    "        new_xyz = new_xyz.permute(0, 2, 1)\n",
    "        new_points_concat = torch.cat(new_points_list, dim=1)\n",
    "        return new_xyz, new_points_concat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44d609d8",
   "metadata": {},
   "source": [
    "### Архітектура PointNet++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetPlusPlus(nn.Module):\n",
    "    def __init__(self, number_of_classes):\n",
    "        super(PointNetPlusPlus, self).__init__()\n",
    "        self.sa1 = PNetSetAbstractionMsg(512, [0.1, 0.2, 0.4], [16, 32, 128], 0,\n",
    "                                         [[32, 32, 64], [64, 64, 128], [64, 96, 128]])\n",
    "        self.sa2 = PNetSetAbstractionMsg(128, [0.2, 0.4, 0.8], [32, 64, 128], 320,\n",
    "                                         [[64, 64, 128], [128, 128, 256], [128, 128, 256]])\n",
    "        self.sa3 = PNetSetAbstraction(1024, None, None, 640 + 3, [256, 512, 1024])\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.drop1 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.drop2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(256, number_of_classes)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        B, _, _ = xyz.shape\n",
    "        l1_xyz, l1_points = self.sa1(xyz, None)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        x = l3_points.view(B, 1024)\n",
    "        x = self.drop1(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.drop2(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x, l3_points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9753f623",
   "metadata": {},
   "source": [
    "### Функції тестування та збереження результатів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    mean_accuracy = []\n",
    "    for j, data in enumerate(loader, 0):\n",
    "        points, target = data\n",
    "        target = target[:, 0]\n",
    "        points = points.transpose(2, 1)\n",
    "        points, target = points.cuda(), target.cuda()\n",
    "        model.eval()\n",
    "        pred, _ = model(points)\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.long().data).cpu().sum()\n",
    "        mean_accuracy.append(correct.item() / float(points.size()[0]))\n",
    "    return np.mean(mean_accuracy)\n",
    "\n",
    "def save_checkpoint(epoch, train_accuracy, test_accuracy, model, optimizer, path, model_name='checkpoint'):\n",
    "    save_path = path + '/%s-%f-%04d.pt' % (model_name, test_accuracy, epoch)\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80ae117e",
   "metadata": {},
   "source": [
    "### Визначення даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попередня обробка даних\n",
    "transformation = transforms.Compose([\n",
    "    Select_Points(1024),\n",
    "    Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "DATASET_PATH = Path(\"../Diploma/ModelNet10\")\n",
    "\n",
    "TrainData = ModelRead(DATASET_PATH, \"train\", transformation)\n",
    "TestData = ModelRead(DATASET_PATH, \"test\", transformation)\n",
    "\n",
    "# Завантаження тренувальних та тестувальниз даних\n",
    "# перемішаних та поділених на частини \n",
    "TrainLoader = DataLoader(TrainData, shuffle=True, batch_size=64)\n",
    "TestLoader = DataLoader(TestData, shuffle=True, batch_size=64)\n",
    "\n",
    "print('Train DataSet len:',len(TrainData))\n",
    "print('Train DataSet Classes:',len(TrainData.classes))\n",
    "print('Test DataSet len:',len(TestData))\n",
    "print('Test DataSet Classes:',len(TestData.classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4afedc6",
   "metadata": {},
   "source": [
    "### Визначення гіперпараметрів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classifier = PointNetPlusPlus(len(TrainData.classes))\n",
    "classifier = classifier.to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "start_epoch = 0\n",
    "optimizer = torch.optim.Adam(\n",
    "        classifier.parameters(),\n",
    "        lr= 1e-4,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-08,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "global_epoch = 0\n",
    "global_step = 0\n",
    "best_tst_accuracy = 0.0\n",
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e1e7001",
   "metadata": {},
   "source": [
    "### Тренування та тестування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc749e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, 10):\n",
    "    print('Epoch %d (%d/%s):' % (global_epoch + 1, epoch + 1, 10))\n",
    "    scheduler.step()\n",
    "    loss_ep = 0\n",
    "    for batch_id, data in tqdm(enumerate(TrainLoader, 0), total=len(TrainLoader), smoothing=0.9):\n",
    "        points = data['Data'].to(device=device)\n",
    "        target = data['Class'].to(device=device)\n",
    "        points = points.transpose(2, 1)\n",
    "        points = points.type(torch.FloatTensor)\n",
    "        optimizer.zero_grad()\n",
    "        scores = classifier(points)\n",
    "        loss = criterion(scores, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        loss_ep += loss.item()\n",
    "    train_acc = evaluate(classifier.eval(), TrainLoader)\n",
    "    acc = evaluate(classifier, TestLoader)\n",
    "\n",
    "\n",
    "    print('\\r Loss: %f' % loss.data)\n",
    "    print('Train Accuracy: %f' % train_acc)\n",
    "    print('\\r Test %s: %f' % (blue('Accuracy'),acc))\n",
    "    \n",
    "    if (acc >= best_tst_accuracy) and epoch > 5:\n",
    "        best_tst_accuracy = acc\n",
    "        logger.info('Save model...')\n",
    "        save_checkpoint(\n",
    "            global_epoch + 1,\n",
    "            train_acc,\n",
    "            acc,\n",
    "            classifier,\n",
    "            optimizer,\n",
    "            str(checkpoints_dir),\n",
    "            'pointnet2')\n",
    "        print('Saving model....')\n",
    "    global_epoch += 1\n",
    "print('Best Accuracy: %f'%best_tst_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
